{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N03A_randomsearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDhruBVOtg1J",
        "outputId": "aa9e1d91-9a33-41d7-a8b6-506285a8fee3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.8.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dP3PNOzYeLcs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, make_scorer, r2_score, accuracy_score, log_loss, confusion_matrix\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "#from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import GlorotUniform, Zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prüfe ob eine CPU für das Training verfügbar ist."
      ],
      "metadata": {
        "id": "54A5dc9Pzdqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl-LWp6ujRL_",
        "outputId": "bc502675-3b4c-490a-deeb-1cfa36bab552"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um die Ergebnisse reproduzierbar zu machen erstellen wir einen random_state und intialisieren die seeds für die RNG."
      ],
      "metadata": {
        "id": "ozaxiuTYzcTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 1\n",
        "tf.random.set_seed(random_state)\n",
        "np.random.seed(random_state)"
      ],
      "metadata": {
        "id": "v7Zc4tvrfIv9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lade die erstellten Trainingsdaten."
      ],
      "metadata": {
        "id": "-wxnoh0-z-Ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/WR2 Brrr/Trainingsdaten_Proj3/training_dataset_ver5.csv', header = None)\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Pf2lRsBOfglk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "77242827-cadf-4a25-af11-120a20cab595"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(38163, 4801)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...  4791  \\\n",
              "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "1     0     0     0     0     0     0     0     0     0     0  ...     1   \n",
              "2     1     1     1     1     1     1     1     1     1     1  ...     1   \n",
              "3     1     1     1     1     1     1     1     1     1     1  ...     0   \n",
              "4     0     0     0     0     0     0     0     0     0     0  ...     1   \n",
              "\n",
              "   4792  4793  4794  4795  4796  4797  4798  4799  4800  \n",
              "0     0     0     0     0     0     0     0     0     0  \n",
              "1     1     1     1     1     1     1     1     1     0  \n",
              "2     1     1     1     1     1     1     1     1     0  \n",
              "3     0     0     0     0     0     0     0     0     0  \n",
              "4     1     1     1     1     1     1     1     1     0  \n",
              "\n",
              "[5 rows x 4801 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5243dd8a-2abb-4aac-8348-363a9773b97d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>4791</th>\n",
              "      <th>4792</th>\n",
              "      <th>4793</th>\n",
              "      <th>4794</th>\n",
              "      <th>4795</th>\n",
              "      <th>4796</th>\n",
              "      <th>4797</th>\n",
              "      <th>4798</th>\n",
              "      <th>4799</th>\n",
              "      <th>4800</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 4801 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5243dd8a-2abb-4aac-8348-363a9773b97d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5243dd8a-2abb-4aac-8348-363a9773b97d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5243dd8a-2abb-4aac-8348-363a9773b97d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1:].values\n",
        "X[:10,]"
      ],
      "metadata": {
        "id": "OtgkpYX1fgom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e71e5a-f2be-409b-9e0a-0c477eacadaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [1, 1, 0, ..., 0, 1, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im folgenden wird der Datensatz auf das Intervall [0,1] normalisiert und ein Train-Test split durchgeführt. Die Normalisierung ist streng genommen nicht notwendig, da unsere Trainingssdaten bereits normalisiert ist."
      ],
      "metadata": {
        "id": "QmXxxrfp0PYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = MinMaxScaler()\n",
        "X = normalizer.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)"
      ],
      "metadata": {
        "id": "wRl0vKw6foVl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lege die Parameterverteilungen für den RandomSearch fest und erstelle das zugehörige dictionary. In der Variable metrics werden die gewünschten Metriken eingetragen, welche während des fittings evaluiert werden. Da diese aber nicht direkt im RandomSearch eingesehen werden können, werden sie vorerst nicht benötigt."
      ],
      "metadata": {
        "id": "M5WBy7yx0qp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size      = [8,16,32,64]\n",
        "epochs          = [50,100,150]\n",
        "learning_rate   = [0.002,0.01,0.1]\n",
        "n_hidden_layers = [2,3,4,5]\n",
        "layer_size      = [100,200,500,1000]\n",
        "dropout_rate    = [0, 0.1, 0.2, 0.5]\n",
        "\n",
        "parameters = {\n",
        "    'batch_size': batch_size,\n",
        "    'epochs': epochs,\n",
        "    'learning_rate' : learning_rate,\n",
        "    'n_hidden_layers' : n_hidden_layers,\n",
        "    'layer_size' : layer_size,\n",
        "    'dropout_rate' : dropout_rate\n",
        "    }\n",
        "\n",
        "# metrics = [tf.keras.metrics.BinaryAccuracy(),\n",
        "#            tf.keras.metrics.BinaryCrossentropy(),\n",
        "#            tf.keras.metrics.AUC(),\n",
        "#            tf.keras.metrics.Precision(),\n",
        "#            tf.keras.metrics.Recall(),\n",
        "#            tf.keras.metrics.TrueNegatives()\n",
        "#            ]\n",
        "metrics = None"
      ],
      "metadata": {
        "id": "fXG2fqTef3o3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der KerasClassifier Wrapper nimmt eine build_fn als Argument, in welcher das Keras Modell erstellt wird. Erstelle in dieser die Netzwerk Architektur und lege die möglichen Hyperparameter fest.\n",
        "\n",
        "In unserem Fall ist die Modell Architektur ein dichtes FFN welches folgendermaßen aufgebaut ist:\n",
        "Input -> DenseLayer -> ActivationFN -> DropoutLayer -> DenseLayer -> ... -> DropoutLayer -> OutputLayer(1 Neuron) -> SigmoidFN"
      ],
      "metadata": {
        "id": "dqCeXVeX1Q8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(learning_rate,n_hidden_layers,layer_size,dropout_rate):\n",
        "    model = Sequential()\n",
        "    \n",
        "    for i in range(n_hidden_layers):\n",
        "        model.add(Dense(units=layer_size,activation = 'relu'))\n",
        "        model.add(tf.keras.layers.Dropout(dropout_rate, seed = random_state+i)) \n",
        "    # Output Layer\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "        \n",
        "    model.compile(loss = 'binary_crossentropy',\n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  metrics = metrics)\n",
        "    return model\n",
        "    \n",
        "model = KerasClassifier(build_model, verbose = 0)"
      ],
      "metadata": {
        "id": "cFLq_npJftcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf2f84f-8505-403c-86a7-804e1fc60b7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Validation Strategy. Da die generierten Trainingsdaten recht umfangreich sind, eignet sich ein 4er-Split. Der CV wird zudem mit einem random state versehen."
      ],
      "metadata": {
        "id": "G-3ruTEN2llx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits = 4, shuffle = True, random_state = random_state)"
      ],
      "metadata": {
        "id": "rPRH0Vwbf-qv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Das Format in welchem der Output in tf.Keras generiert werden macht es notwendig, dass der scikit-learn Cross-Entropy scorer mit einer Toleranz versehen wird."
      ],
      "metadata": {
        "id": "wbfDLkDa27zI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float32neg_log_loss = make_scorer(log_loss, eps = 1e-7)"
      ],
      "metadata": {
        "id": "pF_0y0Y5f9T4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Search\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Erstelle den RandomSearchCV. Interessante Auswertungen sind die Genauigkeit, der Cross-Entropy loss sowie der Recall. Erstelle zudem einen zusätzlichen random state für die Suche, um mehrere kürzere Durchlaufe starten zu können, ohne dabei andere Parameter zu beeinflussen."
      ],
      "metadata": {
        "id": "b6-sGq7w3PiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randomStateSearch = 4\n",
        "randomsearch = RandomizedSearchCV(estimator = model,\n",
        "                                  param_distributions = parameters,\n",
        "                                  n_iter = 15,\n",
        "                                  scoring={'accuracy':'accuracy',\n",
        "                                           'ce':float32neg_log_loss,\n",
        "                                           #'conf_matrix': confusion_matrix_scorer,\n",
        "                                           'recall': 'recall'},   \n",
        "                                  refit = False,\n",
        "                                  cv=cv,\n",
        "                                  random_state = randomStateSearch,\n",
        "                                  return_train_score=True,\n",
        "                                  verbose = 4)"
      ],
      "metadata": {
        "id": "GSby9lyBhxSX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Führe die RandomSearch durch und speichere die Ergebnisse ab."
      ],
      "metadata": {
        "id": "NP9x5o7p3ued"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randomsearch.fit(X_train, y_train, verbose = 0)\n",
        "result_df = pd.DataFrame.from_dict(randomsearch.cv_results_)\n",
        "result_df.to_pickle('/content/drive/MyDrive/WR2 Brrr/Trainingsdaten_Proj3/randomsearch/randsearch_results_rs'+ str(randomStateSearch)+ '.pkl')\n",
        "result_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "1WaawkTCh19r",
        "outputId": "cf9339c2-8681-4305-80b9-8c7470a6defa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
            "[CV 1/4] END batch_size=16, dropout_rate=0.5, epochs=150, layer_size=1000, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.636, test=2.637) recall: (train=0.000, test=0.000) total time=12.1min\n",
            "[CV 2/4] END batch_size=16, dropout_rate=0.5, epochs=150, layer_size=1000, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.636, test=2.637) recall: (train=0.000, test=0.000) total time=11.9min\n",
            "[CV 3/4] END batch_size=16, dropout_rate=0.5, epochs=150, layer_size=1000, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.637, test=2.636) recall: (train=0.000, test=0.000) total time=11.9min\n",
            "[CV 4/4] END batch_size=16, dropout_rate=0.5, epochs=150, layer_size=1000, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.637, test=2.636) recall: (train=0.000, test=0.000) total time=11.8min\n",
            "[CV 1/4] END batch_size=8, dropout_rate=0.1, epochs=50, layer_size=500, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.636, test=2.637) recall: (train=0.000, test=0.000) total time= 5.8min\n",
            "[CV 2/4] END batch_size=8, dropout_rate=0.1, epochs=50, layer_size=500, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.636, test=2.637) recall: (train=0.000, test=0.000) total time= 5.7min\n",
            "[CV 3/4] END batch_size=8, dropout_rate=0.1, epochs=50, layer_size=500, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.637, test=2.636) recall: (train=0.000, test=0.000) total time= 5.8min\n",
            "[CV 4/4] END batch_size=8, dropout_rate=0.1, epochs=50, layer_size=500, learning_rate=0.01, n_hidden_layers=4; accuracy: (train=0.836, test=0.836) ce: (train=2.637, test=2.636) recall: (train=0.000, test=0.000) total time= 5.7min\n",
            "[CV 1/4] END batch_size=16, dropout_rate=0, epochs=150, layer_size=1000, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=1.000, test=0.978) ce: (train=0.006, test=0.359) recall: (train=0.998, test=0.916) total time=10.3min\n",
            "[CV 2/4] END batch_size=16, dropout_rate=0, epochs=150, layer_size=1000, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=1.000, test=0.978) ce: (train=0.006, test=0.361) recall: (train=0.998, test=0.918) total time=10.4min\n",
            "[CV 3/4] END batch_size=16, dropout_rate=0, epochs=150, layer_size=1000, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=0.998, test=0.978) ce: (train=0.037, test=0.357) recall: (train=0.990, test=0.927) total time=10.3min\n",
            "[CV 4/4] END batch_size=16, dropout_rate=0, epochs=150, layer_size=1000, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=0.999, test=0.974) ce: (train=0.018, test=0.424) recall: (train=0.995, test=0.906) total time=10.2min\n",
            "[CV 1/4] END batch_size=64, dropout_rate=0.1, epochs=100, layer_size=100, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=0.999, test=0.974) ce: (train=0.020, test=0.422) recall: (train=0.993, test=0.894) total time= 1.5min\n",
            "[CV 2/4] END batch_size=64, dropout_rate=0.1, epochs=100, layer_size=100, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=0.997, test=0.974) ce: (train=0.054, test=0.418) recall: (train=0.987, test=0.908) total time= 1.5min\n",
            "[CV 3/4] END batch_size=64, dropout_rate=0.1, epochs=100, layer_size=100, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=0.998, test=0.977) ce: (train=0.037, test=0.378) recall: (train=0.994, test=0.911) total time= 1.5min\n",
            "[CV 4/4] END batch_size=64, dropout_rate=0.1, epochs=100, layer_size=100, learning_rate=0.002, n_hidden_layers=3; accuracy: (train=0.997, test=0.973) ce: (train=0.053, test=0.439) recall: (train=0.982, test=0.873) total time= 1.5min\n",
            "[CV 1/4] END batch_size=8, dropout_rate=0.5, epochs=50, layer_size=500, learning_rate=0.002, n_hidden_layers=2; accuracy: (train=0.953, test=0.944) ce: (train=0.756, test=0.904) recall: (train=0.714, test=0.666) total time= 5.1min\n",
            "[CV 2/4] END batch_size=8, dropout_rate=0.5, epochs=50, layer_size=500, learning_rate=0.002, n_hidden_layers=2; accuracy: (train=0.949, test=0.944) ce: (train=0.823, test=0.906) recall: (train=0.688, test=0.664) total time= 5.1min\n",
            "[CV 3/4] END batch_size=8, dropout_rate=0.5, epochs=50, layer_size=500, learning_rate=0.002, n_hidden_layers=2; accuracy: (train=0.940, test=0.938) ce: (train=0.971, test=0.995) recall: (train=0.632, test=0.632) total time= 5.1min\n",
            "[CV 4/4] END batch_size=8, dropout_rate=0.5, epochs=50, layer_size=500, learning_rate=0.002, n_hidden_layers=2; accuracy: (train=0.958, test=0.951) ce: (train=0.676, test=0.788) recall: (train=0.746, test=0.720) total time= 5.0min\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-66cb5e14f815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandomsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/WR2 Brrr/Trainingsdaten_Proj3/randsearch_results_rs'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomStateSearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs = [0,1,2,3,10,11,12]\n",
        "names = ['randsearch_results_rs'+ str(rs_)+ '.pkl' for rs_ in rs]\n",
        "dfs = []\n",
        "for name in names:\n",
        "  dfs.append(pd.read_pickle('/content/drive/MyDrive/WR2 Brrr/Trainingsdaten_Proj3/randomsearch/' + name))\n",
        "\n",
        "results = pd.concat(dfs, axis = 'index', ignore_index = True).sort_values(by = [\"mean_test_accuracy\"])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mseFuGyN44tQ",
        "outputId": "0730ce44-5e9f-4b12-c272-27de8df7b934"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "33     619.682706      7.535112         0.589411        0.009955   \n",
              "29     303.706894      0.716040         0.572701        0.015192   \n",
              "19     490.330584      3.196641         0.522753        0.002357   \n",
              "12     327.589694      0.749676         0.504929        0.007579   \n",
              "37      47.477273      0.113815         0.515726        0.005492   \n",
              "36     107.003731      0.339967         0.517914        0.004168   \n",
              "35     362.295192      2.014605         0.560357        0.032817   \n",
              "30     358.676418      1.283413         0.540255        0.007570   \n",
              "27      59.868248      0.301121         0.584943        0.015693   \n",
              "24     638.202751      1.481174         0.502302        0.006337   \n",
              "21     138.168345      0.269470         0.498021        0.006344   \n",
              "18      98.705741      0.449699         0.494964        0.004267   \n",
              "17     275.143765      3.140614         0.509864        0.008817   \n",
              "15      93.002492      1.176678         0.556531        0.144547   \n",
              "0       86.418277      3.616618         0.520670        0.031083   \n",
              "11     552.308725      5.371141         0.523675        0.008721   \n",
              "6      351.223044      3.108248         0.521332        0.004699   \n",
              "2       49.466538      0.159550         0.515586        0.008502   \n",
              "14     536.530766      4.265240         0.520109        0.010518   \n",
              "4      522.774751      2.583526         0.530686        0.003239   \n",
              "32     435.336044      1.359521         0.598080        0.003695   \n",
              "34     280.696860      1.740303         0.566898        0.007400   \n",
              "5      258.536841      3.477826         0.512234        0.018555   \n",
              "23     255.898172      0.409741         0.484053        0.005191   \n",
              "7       79.755192      0.356731         0.486140        0.006590   \n",
              "8      155.837165      0.595075         0.510431        0.014200   \n",
              "31     159.667074      0.539118         0.567328        0.006649   \n",
              "20      83.948088      0.402150         0.479582        0.002474   \n",
              "26      96.139142      0.323815         0.540826        0.031111   \n",
              "9      200.615424      0.591621         0.531973        0.009987   \n",
              "10      46.557834      3.255818         0.507771        0.034070   \n",
              "25     383.558856      2.979596         0.584141        0.046770   \n",
              "28     107.178306      0.722470         0.558734        0.013059   \n",
              "16     251.292097      2.191406         0.492574        0.001974   \n",
              "39     136.924498      1.011627         0.506652        0.013255   \n",
              "3       47.093890      0.373717         0.507117        0.005327   \n",
              "13     139.240087      0.537156         0.498046        0.009720   \n",
              "1       84.070370      0.581410         0.523855        0.006569   \n",
              "38     135.396681      0.826813         0.499666        0.003221   \n",
              "22     109.867527      0.365747         0.535506        0.009653   \n",
              "\n",
              "   param_n_hidden_layers param_learning_rate param_layer_size param_epochs  \\\n",
              "33                     4                 0.1              200          150   \n",
              "29                     3                 0.1              500          150   \n",
              "19                     5                 0.1              200          150   \n",
              "12                     3                 0.1              200          100   \n",
              "37                     4                 0.1              100           50   \n",
              "36                     5                 0.1              500          100   \n",
              "35                     5                0.01              500           50   \n",
              "30                     2                 0.1              100           50   \n",
              "27                     5                0.01              500           50   \n",
              "24                     3                0.01              500          100   \n",
              "21                     3                 0.1              200          150   \n",
              "18                     3                0.01              500          100   \n",
              "17                     3                0.01              500          150   \n",
              "15                     2                 0.1              500          100   \n",
              "0                      2                 0.1              500           50   \n",
              "11                     5                0.01              200          150   \n",
              "6                      5                0.01              200           50   \n",
              "2                      3                 0.1              500           50   \n",
              "14                     5                0.01              100          150   \n",
              "4                      5                0.01              100          150   \n",
              "32                     5                0.01              100          100   \n",
              "34                     3                0.01              100          150   \n",
              "5                      3                0.01              200          150   \n",
              "23                     2                0.01              500          150   \n",
              "7                      2                0.01              200           50   \n",
              "8                      3                0.01              100          100   \n",
              "31                     3                0.01              100          150   \n",
              "20                     2               0.001              200          100   \n",
              "26                     2               0.001              500           50   \n",
              "9                      5               0.001              500          100   \n",
              "10                     2               0.001              100           50   \n",
              "25                     3               0.001              100           50   \n",
              "28                     3               0.001              500          100   \n",
              "16                     3               0.001              200          150   \n",
              "39                     3               0.001              100          150   \n",
              "3                      2               0.001              500           50   \n",
              "13                     2               0.001              500          150   \n",
              "1                      5               0.001              200           50   \n",
              "38                     3               0.001              200          150   \n",
              "22                     5               0.001              500          100   \n",
              "\n",
              "   param_dropout_rate param_batch_size  ... split3_test_recall  \\\n",
              "33                0.5               16  ...           1.000000   \n",
              "29                0.5               32  ...           1.000000   \n",
              "19                  0               16  ...           0.000000   \n",
              "12                0.5               16  ...           0.000000   \n",
              "37                0.1               64  ...           0.000000   \n",
              "36                0.5               64  ...           0.000000   \n",
              "35                0.1                8  ...           0.000000   \n",
              "30                0.5                8  ...           0.000000   \n",
              "27                0.1               64  ...           0.000000   \n",
              "24                0.2                8  ...           0.000000   \n",
              "21                0.5               64  ...           0.000000   \n",
              "18                0.1               64  ...           0.000000   \n",
              "17                0.5               32  ...           0.000000   \n",
              "15                0.5               64  ...           0.000000   \n",
              "0                 0.1               32  ...           0.000000   \n",
              "11                0.5               16  ...           0.000000   \n",
              "6                 0.2                8  ...           0.000000   \n",
              "2                 0.5               64  ...           0.000000   \n",
              "14                0.1               16  ...           0.000000   \n",
              "4                 0.5               16  ...           0.034455   \n",
              "32                0.1               16  ...           0.000000   \n",
              "34                  0               32  ...           0.888622   \n",
              "5                 0.1               32  ...           0.733974   \n",
              "23                0.2               32  ...           0.600962   \n",
              "7                 0.2               32  ...           0.728365   \n",
              "8                   0               32  ...           0.699519   \n",
              "31                0.5               64  ...           0.705128   \n",
              "20                  0               64  ...           0.893429   \n",
              "26                0.2               32  ...           0.870994   \n",
              "9                 0.1               32  ...           0.905449   \n",
              "10                0.2               64  ...           0.895833   \n",
              "25                0.2                8  ...           0.895833   \n",
              "28                0.5               64  ...           0.842147   \n",
              "16                0.5               32  ...           0.846154   \n",
              "39                0.2               64  ...           0.886218   \n",
              "3                 0.2               64  ...           0.909455   \n",
              "13                0.2               64  ...           0.902244   \n",
              "1                   0               32  ...           0.894231   \n",
              "38                0.2               64  ...           0.891026   \n",
              "22                0.1               64  ...           0.924679   \n",
              "\n",
              "   mean_test_recall  std_test_recall  rank_test_recall  split0_train_recall  \\\n",
              "33         0.250000         0.433013                 7             0.000000   \n",
              "29         0.250000         0.433013                 7             0.000000   \n",
              "19         0.250000         0.433013                 4             1.000000   \n",
              "12         0.000000         0.000000                 3             0.000000   \n",
              "37         0.000000         0.000000                 3             0.000000   \n",
              "36         0.000000         0.000000                 3             0.000000   \n",
              "35         0.000000         0.000000                 3             0.000000   \n",
              "30         0.000000         0.000000                 9             0.000000   \n",
              "27         0.000000         0.000000                 9             0.000000   \n",
              "24         0.000000         0.000000                 5             0.000000   \n",
              "21         0.000000         0.000000                 5             0.000000   \n",
              "18         0.000000         0.000000                 5             0.000000   \n",
              "17         0.000000         0.000000                 5             0.000000   \n",
              "15         0.000000         0.000000                 2             0.000000   \n",
              "0          0.000000         0.000000                 4             0.000000   \n",
              "11         0.000000         0.000000                 3             0.000000   \n",
              "6          0.000000         0.000000                 5             0.000000   \n",
              "2          0.000000         0.000000                 4             0.000000   \n",
              "14         0.000000         0.000000                 3             0.000000   \n",
              "4          0.008614         0.014920                 3             0.000000   \n",
              "32         0.318582         0.318584                 6             0.675033   \n",
              "34         0.443132         0.443135                 5             0.000000   \n",
              "5          0.664023         0.068463                 4             0.605340   \n",
              "23         0.644974         0.048407                 3             0.747397   \n",
              "7          0.678627         0.034265                 3             0.672897   \n",
              "8          0.699447         0.040581                 2             0.772230   \n",
              "31         0.674020         0.047600                 4             0.612016   \n",
              "20         0.885064         0.005749                 2             0.980774   \n",
              "26         0.864644         0.021515                 2             0.901736   \n",
              "9          0.870865         0.075328                 1             0.860347   \n",
              "10         0.902286         0.012337                 1             0.985848   \n",
              "25         0.878259         0.021556                 1             0.958879   \n",
              "28         0.854826         0.012642                 3             0.955407   \n",
              "16         0.861037         0.019473                 1             0.972764   \n",
              "39         0.898479         0.010853                 2             0.995728   \n",
              "3          0.916700         0.012225                 1             0.992256   \n",
              "13         0.886869         0.012382                 2             0.973031   \n",
              "1          0.899886         0.029148                 2             0.949800   \n",
              "38         0.908888         0.017070                 1             0.998131   \n",
              "22         0.922906         0.009496                 1             0.996796   \n",
              "\n",
              "    split1_train_recall  split2_train_recall  split3_train_recall  \\\n",
              "33             0.000000             0.000000             1.000000   \n",
              "29             0.000000             0.000000             1.000000   \n",
              "19             0.000000             0.000000             0.000000   \n",
              "12             0.000000             0.000000             0.000000   \n",
              "37             0.000000             0.000000             0.000000   \n",
              "36             0.000000             0.000000             0.000000   \n",
              "35             0.000000             0.000000             0.000000   \n",
              "30             0.000000             0.000000             0.000000   \n",
              "27             0.000000             0.000000             0.000000   \n",
              "24             0.000000             0.000000             0.000000   \n",
              "21             0.000000             0.000000             0.000000   \n",
              "18             0.000000             0.000000             0.000000   \n",
              "17             0.000000             0.000000             0.000000   \n",
              "15             0.000000             0.000000             0.000000   \n",
              "0              0.000000             0.000000             0.000000   \n",
              "11             0.000000             0.000000             0.000000   \n",
              "6              0.000000             0.000000             0.000000   \n",
              "2              0.000000             0.000000             0.000000   \n",
              "14             0.000000             0.000000             0.000000   \n",
              "4              0.000000             0.000000             0.037373   \n",
              "32             0.000000             0.628137             0.000000   \n",
              "34             0.993858             0.000000             0.979445   \n",
              "5              0.652336             0.722371             0.743727   \n",
              "23             0.605340             0.685798             0.599840   \n",
              "7              0.675567             0.680192             0.736519   \n",
              "8              0.657143             0.737587             0.711159   \n",
              "31             0.718291             0.682595             0.719701   \n",
              "20             0.964486             0.970635             0.979445   \n",
              "26             0.934846             0.944474             0.956220   \n",
              "9              0.993591             0.994661             0.991191   \n",
              "10             0.978371             0.994661             0.993593   \n",
              "25             0.978371             0.964762             0.987186   \n",
              "28             0.971429             0.956487             0.949012   \n",
              "16             0.961282             0.979178             0.970368   \n",
              "39             0.995728             0.993860             0.995996   \n",
              "3              0.996262             0.994394             0.990924   \n",
              "13             0.976502             0.975440             0.984517   \n",
              "1              0.994927             0.996263             0.992258   \n",
              "38             0.995728             0.995729             0.995195   \n",
              "22             0.997330             0.992525             0.996263   \n",
              "\n",
              "    mean_train_recall  std_train_recall  \n",
              "33           0.250000          0.433013  \n",
              "29           0.250000          0.433013  \n",
              "19           0.250000          0.433013  \n",
              "12           0.000000          0.000000  \n",
              "37           0.000000          0.000000  \n",
              "36           0.000000          0.000000  \n",
              "35           0.000000          0.000000  \n",
              "30           0.000000          0.000000  \n",
              "27           0.000000          0.000000  \n",
              "24           0.000000          0.000000  \n",
              "21           0.000000          0.000000  \n",
              "18           0.000000          0.000000  \n",
              "17           0.000000          0.000000  \n",
              "15           0.000000          0.000000  \n",
              "0            0.000000          0.000000  \n",
              "11           0.000000          0.000000  \n",
              "6            0.000000          0.000000  \n",
              "2            0.000000          0.000000  \n",
              "14           0.000000          0.000000  \n",
              "4            0.009343          0.016183  \n",
              "32           0.325793          0.326214  \n",
              "34           0.493326          0.493352  \n",
              "5            0.680944          0.055209  \n",
              "23           0.659594          0.061053  \n",
              "7            0.691294          0.026241  \n",
              "8            0.719529          0.042028  \n",
              "31           0.683151          0.043678  \n",
              "20           0.973835          0.006657  \n",
              "26           0.934319          0.020278  \n",
              "9            0.959948          0.057518  \n",
              "10           0.988118          0.006575  \n",
              "25           0.972300          0.011129  \n",
              "28           0.958084          0.008217  \n",
              "16           0.970898          0.006419  \n",
              "39           0.995328          0.000854  \n",
              "3            0.993459          0.002037  \n",
              "13           0.977372          0.004312  \n",
              "1            0.983312          0.019402  \n",
              "38           0.996196          0.001138  \n",
              "22           0.995728          0.001887  \n",
              "\n",
              "[40 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-823a4ab1-3e26-4da3-936f-93ad1c0faf38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_hidden_layers</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_layer_size</th>\n",
              "      <th>param_epochs</th>\n",
              "      <th>param_dropout_rate</th>\n",
              "      <th>param_batch_size</th>\n",
              "      <th>...</th>\n",
              "      <th>split3_test_recall</th>\n",
              "      <th>mean_test_recall</th>\n",
              "      <th>std_test_recall</th>\n",
              "      <th>rank_test_recall</th>\n",
              "      <th>split0_train_recall</th>\n",
              "      <th>split1_train_recall</th>\n",
              "      <th>split2_train_recall</th>\n",
              "      <th>split3_train_recall</th>\n",
              "      <th>mean_train_recall</th>\n",
              "      <th>std_train_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>619.682706</td>\n",
              "      <td>7.535112</td>\n",
              "      <td>0.589411</td>\n",
              "      <td>0.009955</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.433013</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.433013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>303.706894</td>\n",
              "      <td>0.716040</td>\n",
              "      <td>0.572701</td>\n",
              "      <td>0.015192</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.433013</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.433013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>490.330584</td>\n",
              "      <td>3.196641</td>\n",
              "      <td>0.522753</td>\n",
              "      <td>0.002357</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.433013</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.433013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>327.589694</td>\n",
              "      <td>0.749676</td>\n",
              "      <td>0.504929</td>\n",
              "      <td>0.007579</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>200</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>47.477273</td>\n",
              "      <td>0.113815</td>\n",
              "      <td>0.515726</td>\n",
              "      <td>0.005492</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>107.003731</td>\n",
              "      <td>0.339967</td>\n",
              "      <td>0.517914</td>\n",
              "      <td>0.004168</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>362.295192</td>\n",
              "      <td>2.014605</td>\n",
              "      <td>0.560357</td>\n",
              "      <td>0.032817</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>358.676418</td>\n",
              "      <td>1.283413</td>\n",
              "      <td>0.540255</td>\n",
              "      <td>0.007570</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>59.868248</td>\n",
              "      <td>0.301121</td>\n",
              "      <td>0.584943</td>\n",
              "      <td>0.015693</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>638.202751</td>\n",
              "      <td>1.481174</td>\n",
              "      <td>0.502302</td>\n",
              "      <td>0.006337</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>138.168345</td>\n",
              "      <td>0.269470</td>\n",
              "      <td>0.498021</td>\n",
              "      <td>0.006344</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>98.705741</td>\n",
              "      <td>0.449699</td>\n",
              "      <td>0.494964</td>\n",
              "      <td>0.004267</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>275.143765</td>\n",
              "      <td>3.140614</td>\n",
              "      <td>0.509864</td>\n",
              "      <td>0.008817</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>93.002492</td>\n",
              "      <td>1.176678</td>\n",
              "      <td>0.556531</td>\n",
              "      <td>0.144547</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.418277</td>\n",
              "      <td>3.616618</td>\n",
              "      <td>0.520670</td>\n",
              "      <td>0.031083</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>552.308725</td>\n",
              "      <td>5.371141</td>\n",
              "      <td>0.523675</td>\n",
              "      <td>0.008721</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>351.223044</td>\n",
              "      <td>3.108248</td>\n",
              "      <td>0.521332</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49.466538</td>\n",
              "      <td>0.159550</td>\n",
              "      <td>0.515586</td>\n",
              "      <td>0.008502</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>536.530766</td>\n",
              "      <td>4.265240</td>\n",
              "      <td>0.520109</td>\n",
              "      <td>0.010518</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>0.1</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>522.774751</td>\n",
              "      <td>2.583526</td>\n",
              "      <td>0.530686</td>\n",
              "      <td>0.003239</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034455</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.014920</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037373</td>\n",
              "      <td>0.009343</td>\n",
              "      <td>0.016183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>435.336044</td>\n",
              "      <td>1.359521</td>\n",
              "      <td>0.598080</td>\n",
              "      <td>0.003695</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.318582</td>\n",
              "      <td>0.318584</td>\n",
              "      <td>6</td>\n",
              "      <td>0.675033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.628137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.325793</td>\n",
              "      <td>0.326214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>280.696860</td>\n",
              "      <td>1.740303</td>\n",
              "      <td>0.566898</td>\n",
              "      <td>0.007400</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.888622</td>\n",
              "      <td>0.443132</td>\n",
              "      <td>0.443135</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.993858</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.979445</td>\n",
              "      <td>0.493326</td>\n",
              "      <td>0.493352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>258.536841</td>\n",
              "      <td>3.477826</td>\n",
              "      <td>0.512234</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0.1</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.733974</td>\n",
              "      <td>0.664023</td>\n",
              "      <td>0.068463</td>\n",
              "      <td>4</td>\n",
              "      <td>0.605340</td>\n",
              "      <td>0.652336</td>\n",
              "      <td>0.722371</td>\n",
              "      <td>0.743727</td>\n",
              "      <td>0.680944</td>\n",
              "      <td>0.055209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>255.898172</td>\n",
              "      <td>0.409741</td>\n",
              "      <td>0.484053</td>\n",
              "      <td>0.005191</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600962</td>\n",
              "      <td>0.644974</td>\n",
              "      <td>0.048407</td>\n",
              "      <td>3</td>\n",
              "      <td>0.747397</td>\n",
              "      <td>0.605340</td>\n",
              "      <td>0.685798</td>\n",
              "      <td>0.599840</td>\n",
              "      <td>0.659594</td>\n",
              "      <td>0.061053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>79.755192</td>\n",
              "      <td>0.356731</td>\n",
              "      <td>0.486140</td>\n",
              "      <td>0.006590</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.728365</td>\n",
              "      <td>0.678627</td>\n",
              "      <td>0.034265</td>\n",
              "      <td>3</td>\n",
              "      <td>0.672897</td>\n",
              "      <td>0.675567</td>\n",
              "      <td>0.680192</td>\n",
              "      <td>0.736519</td>\n",
              "      <td>0.691294</td>\n",
              "      <td>0.026241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>155.837165</td>\n",
              "      <td>0.595075</td>\n",
              "      <td>0.510431</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.699519</td>\n",
              "      <td>0.699447</td>\n",
              "      <td>0.040581</td>\n",
              "      <td>2</td>\n",
              "      <td>0.772230</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.737587</td>\n",
              "      <td>0.711159</td>\n",
              "      <td>0.719529</td>\n",
              "      <td>0.042028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>159.667074</td>\n",
              "      <td>0.539118</td>\n",
              "      <td>0.567328</td>\n",
              "      <td>0.006649</td>\n",
              "      <td>3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.674020</td>\n",
              "      <td>0.047600</td>\n",
              "      <td>4</td>\n",
              "      <td>0.612016</td>\n",
              "      <td>0.718291</td>\n",
              "      <td>0.682595</td>\n",
              "      <td>0.719701</td>\n",
              "      <td>0.683151</td>\n",
              "      <td>0.043678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>83.948088</td>\n",
              "      <td>0.402150</td>\n",
              "      <td>0.479582</td>\n",
              "      <td>0.002474</td>\n",
              "      <td>2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>200</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.893429</td>\n",
              "      <td>0.885064</td>\n",
              "      <td>0.005749</td>\n",
              "      <td>2</td>\n",
              "      <td>0.980774</td>\n",
              "      <td>0.964486</td>\n",
              "      <td>0.970635</td>\n",
              "      <td>0.979445</td>\n",
              "      <td>0.973835</td>\n",
              "      <td>0.006657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>96.139142</td>\n",
              "      <td>0.323815</td>\n",
              "      <td>0.540826</td>\n",
              "      <td>0.031111</td>\n",
              "      <td>2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>500</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.870994</td>\n",
              "      <td>0.864644</td>\n",
              "      <td>0.021515</td>\n",
              "      <td>2</td>\n",
              "      <td>0.901736</td>\n",
              "      <td>0.934846</td>\n",
              "      <td>0.944474</td>\n",
              "      <td>0.956220</td>\n",
              "      <td>0.934319</td>\n",
              "      <td>0.020278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>200.615424</td>\n",
              "      <td>0.591621</td>\n",
              "      <td>0.531973</td>\n",
              "      <td>0.009987</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.905449</td>\n",
              "      <td>0.870865</td>\n",
              "      <td>0.075328</td>\n",
              "      <td>1</td>\n",
              "      <td>0.860347</td>\n",
              "      <td>0.993591</td>\n",
              "      <td>0.994661</td>\n",
              "      <td>0.991191</td>\n",
              "      <td>0.959948</td>\n",
              "      <td>0.057518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46.557834</td>\n",
              "      <td>3.255818</td>\n",
              "      <td>0.507771</td>\n",
              "      <td>0.034070</td>\n",
              "      <td>2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.902286</td>\n",
              "      <td>0.012337</td>\n",
              "      <td>1</td>\n",
              "      <td>0.985848</td>\n",
              "      <td>0.978371</td>\n",
              "      <td>0.994661</td>\n",
              "      <td>0.993593</td>\n",
              "      <td>0.988118</td>\n",
              "      <td>0.006575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>383.558856</td>\n",
              "      <td>2.979596</td>\n",
              "      <td>0.584141</td>\n",
              "      <td>0.046770</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.878259</td>\n",
              "      <td>0.021556</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958879</td>\n",
              "      <td>0.978371</td>\n",
              "      <td>0.964762</td>\n",
              "      <td>0.987186</td>\n",
              "      <td>0.972300</td>\n",
              "      <td>0.011129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>107.178306</td>\n",
              "      <td>0.722470</td>\n",
              "      <td>0.558734</td>\n",
              "      <td>0.013059</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.842147</td>\n",
              "      <td>0.854826</td>\n",
              "      <td>0.012642</td>\n",
              "      <td>3</td>\n",
              "      <td>0.955407</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.956487</td>\n",
              "      <td>0.949012</td>\n",
              "      <td>0.958084</td>\n",
              "      <td>0.008217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>251.292097</td>\n",
              "      <td>2.191406</td>\n",
              "      <td>0.492574</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.861037</td>\n",
              "      <td>0.019473</td>\n",
              "      <td>1</td>\n",
              "      <td>0.972764</td>\n",
              "      <td>0.961282</td>\n",
              "      <td>0.979178</td>\n",
              "      <td>0.970368</td>\n",
              "      <td>0.970898</td>\n",
              "      <td>0.006419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>136.924498</td>\n",
              "      <td>1.011627</td>\n",
              "      <td>0.506652</td>\n",
              "      <td>0.013255</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.886218</td>\n",
              "      <td>0.898479</td>\n",
              "      <td>0.010853</td>\n",
              "      <td>2</td>\n",
              "      <td>0.995728</td>\n",
              "      <td>0.995728</td>\n",
              "      <td>0.993860</td>\n",
              "      <td>0.995996</td>\n",
              "      <td>0.995328</td>\n",
              "      <td>0.000854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47.093890</td>\n",
              "      <td>0.373717</td>\n",
              "      <td>0.507117</td>\n",
              "      <td>0.005327</td>\n",
              "      <td>2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>500</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.909455</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>0.012225</td>\n",
              "      <td>1</td>\n",
              "      <td>0.992256</td>\n",
              "      <td>0.996262</td>\n",
              "      <td>0.994394</td>\n",
              "      <td>0.990924</td>\n",
              "      <td>0.993459</td>\n",
              "      <td>0.002037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>139.240087</td>\n",
              "      <td>0.537156</td>\n",
              "      <td>0.498046</td>\n",
              "      <td>0.009720</td>\n",
              "      <td>2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>500</td>\n",
              "      <td>150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.902244</td>\n",
              "      <td>0.886869</td>\n",
              "      <td>0.012382</td>\n",
              "      <td>2</td>\n",
              "      <td>0.973031</td>\n",
              "      <td>0.976502</td>\n",
              "      <td>0.975440</td>\n",
              "      <td>0.984517</td>\n",
              "      <td>0.977372</td>\n",
              "      <td>0.004312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84.070370</td>\n",
              "      <td>0.581410</td>\n",
              "      <td>0.523855</td>\n",
              "      <td>0.006569</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001</td>\n",
              "      <td>200</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.894231</td>\n",
              "      <td>0.899886</td>\n",
              "      <td>0.029148</td>\n",
              "      <td>2</td>\n",
              "      <td>0.949800</td>\n",
              "      <td>0.994927</td>\n",
              "      <td>0.996263</td>\n",
              "      <td>0.992258</td>\n",
              "      <td>0.983312</td>\n",
              "      <td>0.019402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>135.396681</td>\n",
              "      <td>0.826813</td>\n",
              "      <td>0.499666</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>200</td>\n",
              "      <td>150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.891026</td>\n",
              "      <td>0.908888</td>\n",
              "      <td>0.017070</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998131</td>\n",
              "      <td>0.995728</td>\n",
              "      <td>0.995729</td>\n",
              "      <td>0.995195</td>\n",
              "      <td>0.996196</td>\n",
              "      <td>0.001138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>109.867527</td>\n",
              "      <td>0.365747</td>\n",
              "      <td>0.535506</td>\n",
              "      <td>0.009653</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001</td>\n",
              "      <td>500</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924679</td>\n",
              "      <td>0.922906</td>\n",
              "      <td>0.009496</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996796</td>\n",
              "      <td>0.997330</td>\n",
              "      <td>0.992525</td>\n",
              "      <td>0.996263</td>\n",
              "      <td>0.995728</td>\n",
              "      <td>0.001887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 51 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-823a4ab1-3e26-4da3-936f-93ad1c0faf38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-823a4ab1-3e26-4da3-936f-93ad1c0faf38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-823a4ab1-3e26-4da3-936f-93ad1c0faf38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.to_csv('/content/drive/MyDrive/WR2 Brrr/Trainingsdaten_Proj3/randomsearch_results.csv')"
      ],
      "metadata": {
        "id": "vuiQiVCzwua3"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}